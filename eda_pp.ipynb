{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Basis\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Paellete\n",
    "palette = [\"#2D2926FF\", \"#E94B3CFF\"]\n",
    "color_palette = sns.color_palette(palette)\n",
    "\n",
    "# Remove Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set the option to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobleyID</th>\n",
       "      <th>pol</th>\n",
       "      <th>psa</th>\n",
       "      <th>n_donors</th>\n",
       "      <th>nrotb</th>\n",
       "      <th>group_id</th>\n",
       "      <th>dG_exp</th>\n",
       "      <th>n_acceptors</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobley_7532833</td>\n",
       "      <td>-7.491408</td>\n",
       "      <td>23.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobley_2198613</td>\n",
       "      <td>-1.497948</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.24510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobley_9257453</td>\n",
       "      <td>-9.095077</td>\n",
       "      <td>20.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.29</td>\n",
       "      <td>1</td>\n",
       "      <td>2.69900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobley_755351</td>\n",
       "      <td>-13.409148</td>\n",
       "      <td>35.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.29</td>\n",
       "      <td>2</td>\n",
       "      <td>1.27740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobley_9729792</td>\n",
       "      <td>-3.356425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2.05870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mobleyID        pol    psa  n_donors  nrotb  group_id  dG_exp  \\\n",
       "0  mobley_7532833  -7.491408  23.79         0      0       7.0   -3.88   \n",
       "1  mobley_2198613  -1.497948   0.00         0      0       4.0   -0.63   \n",
       "2  mobley_9257453  -9.095077  20.23         1      0       5.0   -7.29   \n",
       "3   mobley_755351 -13.409148  35.25         1      1       5.0   -7.29   \n",
       "4  mobley_9729792  -3.356425   0.00         0      0       NaN   -0.99   \n",
       "\n",
       "   n_acceptors     logP  \n",
       "0            1  0.52988  \n",
       "1            0  1.24510  \n",
       "2            1  2.69900  \n",
       "3            2  1.27740  \n",
       "4            0  2.05870  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"data/group_datagroups_new/0.1/grouped_data.csv\")\n",
    "df = pd.read_csv(\"data/groups/0.1/grouped_data.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobleyID         0\n",
       "pol              0\n",
       "psa              0\n",
       "n_donors         0\n",
       "nrotb            0\n",
       "group_id       172\n",
       "dG_exp           0\n",
       "n_acceptors      0\n",
       "logP             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nan\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobleyID       0\n",
       "pol            0\n",
       "psa            0\n",
       "n_donors       0\n",
       "nrotb          0\n",
       "group_id       0\n",
       "dG_exp         0\n",
       "n_acceptors    0\n",
       "logP           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace null 'group_id' values with 8\n",
    "df[\"group_id\"] = df[\"group_id\"].fillna(8)\n",
    "\n",
    "# Count nan again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"pol\", \"psa\", \"n_donors\", \"nrotb\", \"n_acceptors\", \"logP\"]\n",
    "X = df[features]\n",
    "y = df[\"dG_exp\"]\n",
    "groups = df[\"group_id\"]\n",
    "id_column = \"mobleyID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pol         psa    n_donors       nrotb  n_acceptors  \\\n",
      "count  643.000000  643.000000  643.000000  643.000000   643.000000   \n",
      "mean    -9.583435   20.889207    0.343701    1.629860     1.382582   \n",
      "std     10.516359   23.806500    0.627811    1.971726     1.610850   \n",
      "min   -103.116055    0.000000    0.000000    0.000000     0.000000   \n",
      "25%    -11.689927    0.000000    0.000000    0.000000     0.000000   \n",
      "50%     -7.678724   17.070000    0.000000    1.000000     1.000000   \n",
      "75%     -3.611565   26.300000    1.000000    3.000000     2.000000   \n",
      "max     -0.049148  136.100000    6.000000   12.000000     9.000000   \n",
      "\n",
      "             logP      dG_exp  \n",
      "count  643.000000  643.000000  \n",
      "mean     1.926940   -3.806952  \n",
      "std      1.491136    3.846124  \n",
      "min     -3.585400  -25.470000  \n",
      "25%      1.123300   -5.730000  \n",
      "50%      1.780100   -3.540000  \n",
      "75%      2.569650   -1.220000  \n",
      "max      9.887600    3.430000  \n"
     ]
    }
   ],
   "source": [
    "print(df[features + [\"dG_exp\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_distributions(df, features, figsize=(8, 6), output_dir=None, custom_bins=None):\n",
    "    \"\"\"\n",
    "    Create publication-quality KDE plots for each feature with detailed statistics and consistent bar alignment.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the features\n",
    "    features (list): List of feature names to plot\n",
    "    figsize (tuple): Figure size (width, height) for each plot\n",
    "    output_dir (str, optional): Directory to save plots. If None, plots are displayed.\n",
    "    custom_bins (dict, optional): Dictionary specifying the number of bins for specific features.\n",
    "\n",
    "    Returns:\n",
    "    list: List of generated figure objects\n",
    "    \"\"\"\n",
    "    # Set Seaborn style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"dark\")  # Use a darker color palette for publication quality\n",
    "\n",
    "    # List to store figures\n",
    "    figures = []\n",
    "\n",
    "    # Plot each feature\n",
    "    for col in features:\n",
    "        # Create a new figure for each feature\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "        # Determine the number of bins\n",
    "        if custom_bins and col in custom_bins:\n",
    "            bins = custom_bins[col]\n",
    "        else:\n",
    "            bins = \"auto\"\n",
    "        # bins = None\n",
    "\n",
    "        # Create histogram with consistent bar alignment\n",
    "        sns.histplot(\n",
    "            data=df,\n",
    "            x=col,\n",
    "            stat=\"density\",\n",
    "            kde=True,\n",
    "            ax=ax,\n",
    "            color=\"#1f77b4\",  # Darker blue\n",
    "            alpha=0.6,\n",
    "            bins=bins,  # Use custom bins\n",
    "            line_kws={\"linewidth\": 2.5},  # Thicker KDE line\n",
    "        )\n",
    "\n",
    "        # Calculate statistics\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        median = df[col].median()\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "\n",
    "        # Create statistics text\n",
    "        stats_text = (\n",
    "            f\"Mean: {mean:.2f}\\n\"\n",
    "            f\"Std: {std:.2f}\\n\"\n",
    "            f\"Median: {median:.2f}\\n\"\n",
    "            f\"Q1: {q1:.2f}\\n\"\n",
    "            f\"Q3: {q3:.2f}\"\n",
    "        )\n",
    "\n",
    "        # Add statistics text\n",
    "        ax.text(\n",
    "            0.95,\n",
    "            0.95,\n",
    "            stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment=\"top\",\n",
    "            horizontalalignment=\"right\",\n",
    "            fontsize=10,  # Increase font size for text box\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.9),\n",
    "        )\n",
    "\n",
    "        # Customize the plot\n",
    "        ax.set_title(f\"Distribution of {col}\", fontsize=16, pad=10)\n",
    "        ax.set_xlabel(col, fontsize=14)\n",
    "        ax.set_ylabel(\"Density\", fontsize=14)\n",
    "\n",
    "        # Increase axis line width\n",
    "        ax.spines[\"top\"].set_linewidth(1.5)\n",
    "        ax.spines[\"right\"].set_linewidth(1.5)\n",
    "        ax.spines[\"left\"].set_linewidth(1.5)\n",
    "        ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "\n",
    "        # Increase tick size\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "\n",
    "        # Add rug plot for better visualization\n",
    "        sns.rugplot(data=df, x=col, ax=ax, color=\"gray\", alpha=0.5)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save or display the plot\n",
    "        if output_dir:\n",
    "            # Ensure output directory exists\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            plt.savefig(\n",
    "                os.path.join(output_dir, f\"{col}_distribution.png\"), dpi=300\n",
    "            )  # Publication quality\n",
    "            plt.close(fig)  # Close the figure to free up memory\n",
    "        else:\n",
    "            figures.append(fig)\n",
    "\n",
    "    # If not saving, return list of figures\n",
    "    return figures if output_dir is None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify custom bins for 'psa' and 'pol'\n",
    "custom_bins = {\n",
    "    \"psa\": 10,\n",
    "    \"pol\": 8,\n",
    "    \"n_donors\": 7,\n",
    "    \"n_acceptors\": 1,\n",
    "    \"nrotb\": 1,\n",
    "}\n",
    "\n",
    "# Call the function with custom bins\n",
    "figures = plot_distributions(\n",
    "    df,\n",
    "    features=features,\n",
    "    custom_bins=custom_bins,\n",
    "    output_dir=\"plots/eda/\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[features + [\"dG_exp\"]].corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = df[\"group_id\"].value_counts()\n",
    "print(\"Group distribution:\")\n",
    "print(group_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "group_counts.plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of Groups\")\n",
    "plt.xlabel(\"Group ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axs[i].scatter(df[feature], df[\"dG_exp\"])\n",
    "    axs[i].set_xlabel(feature)\n",
    "    axs[i].set_ylabel(\"dG_exp\")\n",
    "    axs[i].set_title(f\"{feature} vs dG_exp\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby(\"group_id\")[features + [\"dG_exp\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variables = [\"dG_exp\", \"pol\", \"psa\", \"n_donors\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    data = df[var]\n",
    "\n",
    "    # Calculate IQR\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "\n",
    "    # Plot\n",
    "    axs[i].boxplot(data)\n",
    "    axs[i].scatter(np.ones(len(outliers)), outliers, color=\"red\", s=20)\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "    print(f\"{var}:\")\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "    print(f\"Percentage of outliers: {len(outliers) / len(data) * 100:.2f}%\")\n",
    "    print(f\"Range of outliers: {outliers.min()} to {outliers.max()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# List of variables to analyze\n",
    "variables = [\"pol\", \"psa\", \"n_donors\", \"nrotb\", \"n_acceptors\", \"dG_exp\"]\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = df[variables].apply(lambda x: skew(x))\n",
    "\n",
    "print(\"Skewness for each variable:\")\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "\n",
    "\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column=\"dG_exp\"):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        data = df[self.column]\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(data >= lower_bound) & (data <= upper_bound)]\n",
    "        return df\n",
    "\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, pol_transformer=None):\n",
    "        self.pol_transformer = pol_transformer\n",
    "        self.columns = [\n",
    "            \"pol\",\n",
    "            \"n_acceptors\",\n",
    "            \"n_donors\",\n",
    "            \"nrotb\",\n",
    "            \"psa\",\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.pol_transformer.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        X_[self.columns] = self.pol_transformer.transform(X_[self.columns])\n",
    "        return X_\n",
    "\n",
    "\n",
    "class CustomStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        columns=[\n",
    "            \"pol\",\n",
    "            \"psa\",\n",
    "            \"logP\",\n",
    "            \"n_acceptors\",\n",
    "            \"n_donors\",\n",
    "            \"nrotb\",\n",
    "        ],\n",
    "    ):\n",
    "        self.columns = columns\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        X_[self.columns] = self.scaler.transform(X_[self.columns])\n",
    "        return X_\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"outlier_remover\", OutlierRemover()),\n",
    "        (\n",
    "            \"custom_transformer\",\n",
    "            CustomTransformer(pol_transformer=PowerTransformer(method=\"yeo-johnson\")),\n",
    "        ),\n",
    "        (\"standard_scaler\", CustomStandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Apply the pipeline\n",
    "df_processed = preprocessing_pipeline.fit_transform(df)\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Processed shape:\", df_processed.shape)\n",
    "\n",
    "# Check the first few rows of the processed data\n",
    "print(df_processed.head())\n",
    "\n",
    "# Verify the transformations\n",
    "print(\"\\nMean of scaled features:\")\n",
    "print(df_processed[[\"pol\", \"psa\", \"dG_exp\", \"logP\"]].mean())\n",
    "print(\"\\nStandard deviation of scaled features:\")\n",
    "print(df_processed[[\"pol\", \"psa\", \"dG_exp\", \"logP\"]].std())\n",
    "\n",
    "print(\"\\nSkewness of log-transformed 'pol':\", skew(df_processed[\"pol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 12))\n",
    "\n",
    "# Flatten the 2D array of axes, but keep it as a 2D array\n",
    "axs_flat = axs.flatten()\n",
    "\n",
    "for i, col in enumerate(features + [\"dG_exp\"]):\n",
    "    if i < 6:\n",
    "        # For the first two rows, use axes as normal\n",
    "        ax = axs_flat[i]\n",
    "    else:\n",
    "        # For the last plot, use the center axis in the last row\n",
    "        ax = axs[2, 1]\n",
    "\n",
    "    ax.hist(df_processed[col], bins=30)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Remove the unused subplots\n",
    "fig.delaxes(axs[2, 0])\n",
    "fig.delaxes(axs[2, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# List of variables to analyze\n",
    "variables = [\"pol\", \"psa\", \"n_donors\", \"nrotb\", \"n_acceptors\", \"dG_exp\"]\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = df_processed[variables].apply(lambda x: skew(x))\n",
    "\n",
    "print(\"Skewness for each variable:\")\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as a csv file\n",
    "df_processed.to_csv(\"groups_new/0.1/grouped_data_without_outliers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"custom_transformer\",\n",
    "            CustomTransformer(pol_transformer=PowerTransformer(method=\"yeo-johnson\")),\n",
    "        ),\n",
    "        (\"standard_scaler\", CustomStandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Apply the pipeline\n",
    "df_processed_with_outliers = preprocessing_pipeline.fit_transform(df)\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Processed shape:\", df_processed.shape)\n",
    "\n",
    "# Check the first few rows of the processed data\n",
    "print(df_processed_with_outliers.head())\n",
    "\n",
    "# Verify the transformations\n",
    "print(\"\\nMean of scaled features:\")\n",
    "print(df_processed_with_outliers[[\"pol\", \"psa\", \"dG_exp\", \"logP\"]].mean())\n",
    "print(\"\\nStandard deviation of scaled features:\")\n",
    "print(df_processed_with_outliers[[\"pol\", \"psa\", \"dG_exp\", \"logP\"]].std())\n",
    "\n",
    "print(\"\\nSkewness of log-transformed 'pol':\", skew(df_processed_with_outliers[\"pol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as a csv file\n",
    "df_processed_with_outliers.to_csv(\n",
    "    \"groups_new/0.1/grouped_data_with_outliers.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
